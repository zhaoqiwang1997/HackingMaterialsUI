## Getting Started

For now, you can run the backend application by running:

```sh
FLASK_APP=src/main.py flask run
```

This will run the Flask backend server, listening on your host machine on port 5000. You should be able to access the application at `127.0.0.1:5000`.

For a more complete development environment, use Virtualenv and Docker as described below.

You will need both frontend and backend `.env` files for this product. These can be generated by running the following command in the backend folder. Windows users can replace python3 with python    
`python3 ./create_envs.py <path to root of git project>`

You will need a copy of the Google API key for the following variable    
REACT_APP_GOOGLE_CLIENT_ID
## Development environment

### Virtualenv

`virtualenv` is a Python tool for maintaining a development environment, including:

- Library dependencies
- Packages installed (e.g. using `pip`)
- Choice of Python interpreter

Using a virtual environment ensures that team members are using, for example, the same versions of all dependent libraries and the same Python version.

Virtual environments are typically not committed to Git repositories. Instead:

- Create a virtual environment by running `python3 -m venv venv`
- Activate the virtual environment by running `source venv/bin/activate`
  - This works for POSIX shells (`bash` and `zsh` but may be different for e.g. Powershell)
- While the virtual environment is active, any dependencies you install using `pip` become part of the environment. They are not installed to your system's main Python environment.
- After installing a package, run `pip freeze > requirements.txt` to add it to the list of required packages.
- To make sure your environment is up-to-date with other developers, run `pip install -r requirements.txt` to install all of the packages listed in the requirements file.
- When you're done using it, deactivate the virtual environment by running `Deactivate`.

### Docker

> To test **without** using Docker:
> 
> `FLASK_APP=src/main.py flask run`

Docker is a tool for managing isolated runtime environments (called "containers"). You can install Docker by following the Docker guide (linked below).

You can think of it as a combination of:

- A way to run virtual machines
  - But it's much more efficient
  - And makes it easier to access host machine resources, for example network ports and filesystems
- A way to build custom virtual machines, just like `make` can be used to build binaries or applications
  - The build instructions are described by the `Dockerfile` file


Bear in mind though that **containers are not virtual machines** - that analogy is useful for describing an overview of what Docker does, but it is not accurate.

The two most important things you can do with Docker are:

- Build container **images**, for example by running: `docker image build -t flask-docker .`
  - A container *image* is like a compiled program: it does nothing unless it is run
  - Unlike a program though, it doesn't exist in an obvious way on the filesystem. The Docker runtime is responsible for managing images.
  - `-t flask-docker` tells Docker to "tag" the image with the string "flask-docker". You can refer to Docker objects (including images) by their hash, but naming them makes it easier.
  - The `.` tells Docker to use the Docker file in the current directory. You could provide a path to another directory instead.
- Run a container image, for example by running `docker run -d -p 80:5000 flask-docker`
  - Running an image produces an object called a "container" - this is like a process, just as an image is like a compiled program.
  - The `-d` argument tells Docker to "detach" the container - to run it in the background and not show it's output.
  - The `-p 80:5000` argument tells Docker to map port 80 on the host machine to port 5000 inside the container.
    If you're building a Flask application (which by default listens for requests on port 5000), this means that you would access the application by navigating to port 80 on the host machine.
  - `flask-docker` is the tag of the image we want to run.

Once a container is running, it is given a tag by the Docker runtime. This tag is separate to the tag of the image.

You can view running containers by running `docker ps`.

When you're finished with a container, you can kill it by running `docker kill <container-tag>`

For more information, you can go through the [Docker getting started guide](https://docs.docker.com/get-started/), or refer to their [reference documentation](https://docs.docker.com/reference/).    
   
___       
    
### **Docker Compose** 
Creates and runs two containers:
- A container with Postgress running on port 5432
- A container with PGAdmin (UI for db administration) on port 5050. See [PGAdmin4 Docs](https://www.pgadmin.org/docs/pgadmin4/6.13/index.html)


`Docker compose` can automate the process of setting up & managing multiple containers. see [Install Docker Compose ](https://docs.docker.com/compose/install/)    

Before running the command below create a .env file in this directory and add the following lines
>POSTGRES_USER="db_user"   
POSTGRES_PASS="somehardpassword"   
PGA_USER="user@gmail.com"   
PGA_PASS="anotherhardpassword"

Replace the text inside the inverted commas with appropriate email/password/usernames   

Then create a .pgpassfile in the postgres-init folder and add the following line
>pg_db:5432:ha_db:username:password    

Replacing username and password with the postgres username and password chosen above

Running `docker compose up -d` in this folder will set up and run the two containers with persistant storage.    

If making changes to the .env file, post setup, you may need to delete the persistant storage as follows:   
`docker volume rm backend_postgres-data`    
`docker volume rm backend_pgadmin-data` 

**Warning!** this will delete all existing table data in the database


If you'd like to run Flask inside Docker as well (e.g. if you're only working on the front-end), you can run `docker
compose up --profile backend -d` to start all the containers, including Flask.

To stop the containers, run `docker compose down`, or `docker compose --profile backend down` if Flask is running in a container.

> NOTE use `docker compose` and not `docker-compose`. Docker compose has now been baked into docker and is usually more up to date than `docker-compose`.

___       
    
### **Postgres Database** 
Once the database is up and running run `pytest` from this folder. If the tests fail, try accessing PGAdmin through port 5050, delete all tables and run `pytest` again.


___

### **Celery task manager**
Celery can execute long running tasks without affecting other requests through Flask

To install:
- install the latest libraries from requirements.txt
- update entries in .env file. replacing blurred out items with your own usernames/passwords 
![image](https://user-images.githubusercontent.com/15170494/193798329-164434c3-3766-4256-8c3e-8e246577e542.png)

**There are two options to run Celery**
1. Run `docker compose up -d` and then run Flask. This is the preferred method for development
2. Run `docker compose --profile backend up -d`. This will be the method for final deployment

It is strongly suggested to get the featurizer and ML methods working outside of Celery and then contact Dara O hEidhin to get them working with Celery.


Tested by checking the following endpoints
### Create user test data
http://127.0.0.1:5000/db_create_test_data

### Create a new long running task
http://127.0.0.1:5000/create_long_task/test@test.com

### This endpoint can be polled to get live updates on current task
http://127.0.0.1:5000/task_status/`process id copied from create_long_task`

### Check ALL running tasks
http://127.0.0.1:5000/running_tasks
or using Flower to help with debugging
http://127.0.0.1:8888/dashboard
![image](https://user-images.githubusercontent.com/15170494/190885378-80673b7c-8d01-4cf7-9e8e-9831405ef8bf.png)

### Kill running task
http://127.0.0.1:5000/kill_task/`process id copied from create_long_task`   
eg  
http://127.0.0.1:5000/kill_task/5d91075b-e122-49f4-a046-c53618ab5990

### **Common Issues**    
If you are getting errors try the following
- Delete/rebuild celery-worker & ha_api Docker images, especially if the requirements.txt has been updated
- Ensure no local process is usng port 5000
- These instructions have been tested and are working on Ubuntu 22.04 and Windows 11.

Running the commands below, in the backend folder, will completely reset **ALL** containers/volumes/images.    
   

```diff
- ALL DATABASE DATA WILL BE LOST!!
```

```
docker compose down
docker rm -f $(docker ps -a -q)
docker rmi $(docker images -a -q)
docker volume rm $(docker volume ls -q)
docker system prune -a
docker compose --profile backend --profile frontend up -d 
```
___

### **Deployment**
To deploy the latest changes in an existing Ubuntu 22.04 VM run the following commands   

[comment]: <> (Remove checkout line before merging PR#101)
```
sudo apt update & sudo apt install git
git clone https://github.com/COMP90082-2022-SM2/HA-2022-SM2.git 
cd HA-2022-SM2/src/backend/
git checkout spike/deployment_presentation || true
sudo chmod +x ./deploy_on_ubuntu22_04.sh
./deploy_on_ubuntu22_04.sh
```   

There are two additional files, ignored by git, that are needed to replicate this deployment. These allow us to serve our site using HTTPS.    

![image](https://user-images.githubusercontent.com/15170494/195244703-8b5dd9a4-3389-4ada-b563-e34a2210bc25.png)

These will be replaced by files generated though [https://letsencrypt.org/](https://letsencrypt.org/) in the near future.

**NOTE** A full deployment script will be developed for installation on a new Nectar VM with instructions to be added below.
 